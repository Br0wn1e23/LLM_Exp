{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LaptopBraun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##Functions and libraries\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from fpdf import FPDF\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "##Point to the local server and the model\n",
    "client = OpenAI(base_url=\"http://127.0.0.1:1234/v1\", api_key=\"lm-studio\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "##Dataset\n",
    "# Decode the review froms the dataset\n",
    "def decode_reviews(sequences):\n",
    "    return [\n",
    "        \" \".join([reverse_word_index.get(i - 3, \"?\") for i in sequence[1:]])\n",
    "        for sequence in sequences\n",
    "    ]\n",
    "\n",
    "\n",
    "##Normal Prompting procedure\n",
    "# API access to the model\n",
    "def prompt_model(prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama-3-8b-lexi-uncensored\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Decide whether the entire prompt you receive is either a positive or a negative movie review. Only answer with a single digit, use '1' for positive or with '0' for negativ. Do not answer with anything else than '1' or '0'.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "##RAG Magic\n",
    "# Create vector embeddings for the reviews\n",
    "def encode_text_list(text_list):\n",
    "    embeddings = [model.encode(text) for text in text_list]\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# return the indices of the top n relevant reviews for retrieval\n",
    "def calculate_top_n_similarities(prompt, stored_embeddings, top_n=3):\n",
    "    # Encode the new prompt\n",
    "    prompt_embedding = model.encode(prompt)\n",
    "\n",
    "    # Calculate cosine similarity with each stored embedding\n",
    "    similarities = [\n",
    "        1 - cosine(prompt_embedding, emb) for emb in stored_embeddings\n",
    "    ]  # 1 - cosine_distance = cosine_similarity. The higher the value, the more similar the vectors are\n",
    "\n",
    "    # Get the indices of the top n similarities\n",
    "    top_n_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "\n",
    "    return top_n_indices\n",
    "\n",
    "\n",
    "# construct context query for the model\n",
    "def integrate_reviews(stored_reviews, top_n_indices):\n",
    "    # Define ordinal words for readability\n",
    "    ordinals = [\n",
    "        \"The most similar\",\n",
    "        \"The second most similar\",\n",
    "        \"The third most similar\",\n",
    "        \"The fourth most similar\",\n",
    "        \"The fifth most similar\",\n",
    "        \"The sixth most similar\",\n",
    "        \"The seventh most similar\",\n",
    "        \"The eighth most similar\",\n",
    "        \"The ninth most similar\",\n",
    "        \"The tenth most similar\",\n",
    "    ]\n",
    "    # Construct the formatted string by integrating the reviews in the correct order\n",
    "    integrated_string = \"Decide whether the entire prompt you receive is either a positive or a negative movie review. Only answer with a single digit, use '1' for positive or with '0' for negativ. Do not answer with anything else than '1' or '0'. Use the ratings of the following similar reviews to make your decision. \"\n",
    "    for i, idx in enumerate(top_n_indices):\n",
    "        # Get the ordinal word based on index position, or use \"next\" if ordinals are exceeded\n",
    "        ordinal_word = ordinals[i] if i < len(ordinals) else \"next\"\n",
    "        # Append the formatted review to the integrated string\n",
    "        integrated_string += f\"{ordinal_word} review, {stored_reviews[idx]}\"\n",
    "\n",
    "    return integrated_string.strip()\n",
    "\n",
    "\n",
    "# RAG-prompts for the model\n",
    "def RAG_prompt_model(prompt):\n",
    "    top_n_indices = calculate_top_n_similarities(prompt, stored_embeddings, top_n=3)\n",
    "    content_prompt = integrate_reviews(review_list, top_n_indices)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama-3-8b-lexi-uncensored\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": content_prompt,\n",
    "            },\n",
    "            {\"role\": \"user\", \n",
    "             \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "# Generate RAG document for AnythingLLM\n",
    "def write_reviews_to_txt(reviews, ratings, output_filename=\"movie_reviews.txt\"):\n",
    "    # Check that both lists have the same length\n",
    "    if len(reviews) != len(ratings):\n",
    "        raise ValueError(\"The number of reviews and ratings must be the same.\")\n",
    "\n",
    "    try:\n",
    "        with open(output_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "            # Iterate through reviews and ratings\n",
    "            for review, rating in zip(reviews, ratings):\n",
    "                # Format the review text\n",
    "                formatted_review = f'The review: \"{review}\" was rated \"{rating}\".\\n'\n",
    "\n",
    "                # Write the formatted review to the file\n",
    "                file.write(formatted_review)\n",
    "                file.write(\"\\n\")  # Add a blank line between reviews\n",
    "\n",
    "        print(f\"Text file '{output_filename}' has been created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving text file: {e}\")\n",
    "\n",
    "\n",
    "# generate list of reviews and ratings\n",
    "def store_reviews_with_ratings(reviews, ratings):\n",
    "    # Check that both lists have the same length\n",
    "    if len(reviews) != len(ratings):\n",
    "        raise ValueError(\"The number of reviews and ratings must be the same.\")\n",
    "\n",
    "    # List to store the formatted reviews with ratings\n",
    "    formatted_reviews = []\n",
    "\n",
    "    # Iterate through reviews and ratings\n",
    "    for review, rating in zip(reviews, ratings):\n",
    "        # Format the review text\n",
    "        formatted_review = f'the review: \"{review}\" was rated \"{rating}\".'\n",
    "\n",
    "        # Append the formatted review to the list\n",
    "        formatted_reviews.append(formatted_review)\n",
    "\n",
    "    return formatted_reviews\n",
    "\n",
    "\n",
    "# Working in bigger batches with progress feedback\n",
    "def batch_prompt_model(prompts, mode=\"normal\"):\n",
    "    results = []\n",
    "    for p in prompts:\n",
    "        if mode == \"normal\":\n",
    "            results.append(prompt_model(p))\n",
    "        elif mode == \"RAG\":\n",
    "            results.append(RAG_prompt_model(p))\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid mode '{mode}'.\")\n",
    "        if len(results) % 10 == 0:\n",
    "            print(f\"Completed {len(results)} prompts.\")\n",
    "    return results\n",
    "\n",
    "\n",
    "##Handling unusual outputs\n",
    "# Helper funtion to handle weird outputs\n",
    "def convert_outputs(strings):\n",
    "    result = []\n",
    "    weird = 0\n",
    "    skipped = 0\n",
    "    skipped_indices = []\n",
    "\n",
    "    for i, s in enumerate(strings):\n",
    "        if s != \"1\" and s != \"0\":\n",
    "            weird += 1\n",
    "        # Filter out any characters that are not '1' or '0'\n",
    "        cleaned = \"\".join([char for char in s if char in \"10\"])\n",
    "\n",
    "        # Convert to integer if the cleaned string is exactly \"1\" or \"0\"\n",
    "        if cleaned == \"1\":\n",
    "            result.append(1)\n",
    "        elif cleaned == \"0\":\n",
    "            result.append(0)\n",
    "        else:\n",
    "            # Handle unexpected cases if needed; here we skip them\n",
    "            print(f\"Warning: Unrecognized format '{s}', skipping.\")\n",
    "            print(\"\")\n",
    "            skipped += 1\n",
    "            skipped_indices.append(i)\n",
    "    if weird > 0:\n",
    "        print(f\"This batch query produced {weird} weird outputs.\")\n",
    "    if skipped > 0:\n",
    "        print(\n",
    "            f\"Additionally, it skipped {skipped} outputs that did not contain 1 or 0 at all.\"\n",
    "        )\n",
    "    return result, skipped_indices\n",
    "\n",
    "\n",
    "# delete the skipped indices from the list if needed\n",
    "def clean_y(y, skipped_indices):\n",
    "    if len(skipped_indices) > 0:\n",
    "        print(f\"Warning: removing {len(skipped_indices)} skipped outputs from y.\")\n",
    "        return [y[i] for i in range(len(y)) if i not in skipped_indices]\n",
    "    else:\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test normal, non-augemented prompting first.\n",
    "The dataset contains movie reviews either rated positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Dataset\n",
    "# IMDB dataset preparation\n",
    "# Reverse the word index to create a mapping from integer indices to words\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
    "\n",
    "#Load dataset\n",
    "(train_x, train_y), (test_x, test_y) = imdb.load_data(num_words=100000, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 10 prompts.\n",
      "Completed 20 prompts.\n",
      "Completed 30 prompts.\n",
      "Completed 40 prompts.\n",
      "Completed 50 prompts.\n",
      "Completed 60 prompts.\n",
      "Completed 70 prompts.\n",
      "Completed 80 prompts.\n",
      "Completed 90 prompts.\n",
      "Completed 100 prompts.\n",
      "Accuracy of standard prompting: 0.86\n"
     ]
    }
   ],
   "source": [
    "#Select a subset of the dataset and try the basic model\n",
    "set_size = 100\n",
    "x = decode_reviews(test_x[:set_size])\n",
    "cats, ids = convert_outputs(batch_prompt_model(x))\n",
    "valid_test_y = clean_y(test_y[:set_size], ids)\n",
    "print(f\"Accuracy of standard prompting: {accuracy_score(valid_test_y, cats)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we will test the simple RAG implementation set-up in this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate RAG Knowledge-Base\n",
    "RAG_size = 20000\n",
    "train_y_RAG = [\"positive\" if i == 1 else \"negative\" for i in train_y]\n",
    "review_list = store_reviews_with_ratings(decode_reviews(train_x[:RAG_size]), train_y_RAG[:RAG_size])\n",
    "stored_embeddings = encode_text_list(review_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 10 prompts.\n",
      "Completed 20 prompts.\n",
      "Completed 30 prompts.\n",
      "Completed 40 prompts.\n",
      "Completed 50 prompts.\n",
      "Completed 60 prompts.\n",
      "Completed 70 prompts.\n",
      "Completed 80 prompts.\n",
      "Completed 90 prompts.\n",
      "Completed 100 prompts.\n",
      "Warning: Unrecognized format 'I will decide whether the entire prompt you receive is either a positive or a negative movie review. Only answer with a single digit, use '1' for positive or with '0' for negative. Do not answer with anything else than '1' or '0'. Use the ratings of the following similar reviews to make your decision.\n",
      "\n",
      "The most similar review, the review: \"seriously crappy movie br br first off the movie starts with a cop and his partner parked outside of a warehouse furniture store the bad cop takes a girl which they had pulled over into the warehouse' s attic while the newbie cop sits outside and ponders what could be happening up there the bad cop eventually returns with a heavy duffel bag and the newbie cop doesn't think there are any problems but he still wonders what was in the bag so he asks gets a bullshit response and then he thinks everything is ok for now br br the bad cop repeats this process and even once with a tit scene made it slightly better but eventually people start to catch on which took awhile considering how f ing obvious it was one girl gets a voodoo curse placed on her just in case she dies like ya do now the bad cop eventually kills this magically protected bitch and then he gets rid of the duffel bagged body br br since she had the oogey boogey magic put on her she comes back with lots of eye shadow on which is supposed to indicate that she may be a zombie also the magic curse causes all of the other girls to become eye shadow monsters some of the girls meet up with a dude who is apparently a currency specialist and he offers them a ride they look normal to him apparently but when the girls see other people such as the one girl's husband he freaks out because she is hideous some people freak out but others don't even notice massive plot hole br br so to wrap it up the eye shadow monsters kill the bad cop who in turn ends up becoming a zombie in the last scene it was as though they were trying to prep us for a sequel like anyone would want to see part 2 of this cow dropping\" was rated \"negative\".\n",
      "\n",
      "The second most similar review, the review: \"this is available on a drive-in double feature from dark sky films and since i just had finished up barracuda i watched this too this is a film that proves to be incredibly ambitious and inept at the same time br br we begin with two young ladies wandering the streets of some foreign town but where exactly are they they stop to look at necklaces from some chinese vendor and try on chinese style clothes at a shop but then we see some aztec dancers and all the while these girls are being followed by two guys who eventually drop whatever stealth they didn't have to chase the girls on a wild run though the town and they finally catch them br br it seems that one of the girls has a coin on a string around her neck and these guys want to find the loot and where did she get it so in flashback we go back to find out and how did they know she had this coin hard to say really br br now back in the day when these two women were 10 years old they were out with their sisters and their sister's boyfriends on a boat and after stopped to get air in their tanks they tow this young boy back to his home dock only to have his grandpa come out invite the young 'uns up for herbal tea with granny but not everyone has the tea todd has gone back to the boat to check on the young girls and then when they're away from it the boat blows up and when they get back to the house their friends have mysteriously disappeared well it seems as though these kindly folk raise their own vegetables but they wait for the meat to drop by for a spell and serve it herbal tea br br but the girls and todd did leave the island but now they're returning escorted by their captors and they're there to find the treasure despite the fact that no one ever showed the girls where it was before there also seems to be someone else on the island and the thugs mysteriously begin to die one by one and since there's only three it doesn't take long and there's even a sort of happy ending which will leave the viewer every bit as baffled as they were throughout the rest of the film br br the two thugs seem to be speed freaks with anger issues and combined with no acting ability they're borderline hilarious the hillbilly type family is also devoid of acting ability despite the fact that the grandpa is hank worden who appeared in many films and tv shows the action is confusing the locales are even more confusing and the island looks like southern california br br so what the hell is this i'm not sure but it certainly is worth seeing once so you can think or say huh 4 out of 10 very bizarre\" was rated \"negative\".\n",
      "\n",
      "The third most similar review, the review: \"first off i'm a dedicated fan of modesty's and have been reading the comics since i was a child and i have found the earlier movies about our heroine unsatisfying but where they fail this one rocks br br well then here we go ms blaise is working for a casino a gang of robbers comes along and she starts gambling for her friends lives if the robber wins one round she'll have to tell him about herself if she wins two times in a row one of the staff members goes free sounds stupid yeah well i'm not that good at explaining either br br she tells him about growing up in a war zone without parents or friends about her helping an old man in the refugee camp and how they escape living by nature's own rules they hunt for food and he teaches her to read and fight as they approach civilization they get caught up in a war and as they are taken for rebellions they are being shot at and the old man dies which leaves her to meet the city by herself br br then she meets the man who's casino she's now working for and there the story ends br br what is to follow is that there's an awesome fight and the lines are totally cool alexandra staden is a terrific modesty blaise just as modest and strong graceful and intellectual as the comic one br br feels awkward though too hear modesty speak with a slightly broken accent but that's not relevant since the comic book blaise can't speak out loud but certainly must have a somewhat existing accent not to mention that it's weird everybody's speaking english in the balkan br br the acting is really good even the child who personifies the young blaise must have a applaud br br my favorite part must be where she rips up her dress to kick the stupid robber's ass totally awesome d i can't wait until the real adventure begins in the next movie s br br watch it you won't be disappointed\" was rated \"positive\".\n",
      "\n",
      "Based on these reviews, I would rate this review as follows: 0', skipping.\n",
      "\n",
      "Warning: Unrecognized format 'I would rate this review as \"negative\". The reviewer criticizes the film's script, calling it weak, and specifically points out the coincidental meeting of Joe and Bill. They also mention that the film has a gruesome ending, which may be off-putting to some viewers. Overall, the tone of the review is critical and disapproving.', skipping.\n",
      "\n",
      "This batch query produced 17 weird outputs.\n",
      "Additionally, it skipped 2 outputs that did not contain 1 or 0 at all.\n",
      "Warning: removing 2 skipped outputs from y.\n",
      "Accuracy of RAG prompting: 0.826530612244898\n"
     ]
    }
   ],
   "source": [
    "cats, ids = convert_outputs(batch_prompt_model(x, mode=\"RAG\"))\n",
    "valid_test_y = clean_y(test_y[:set_size], ids)\n",
    "print(f\"Accuracy of RAG prompting: {accuracy_score(valid_test_y, cats)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
